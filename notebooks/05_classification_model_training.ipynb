{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. ML - Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('../data/processed/campana_marketing.csv', parse_dates=['Dt_Customer'])\n",
    "\n",
    "# Convertir la columna 'Income' de float64 a int64\n",
    "df['Income'] = df['Income'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra variable objetivo ser치 `AcceptedCmp`: 0 no se ha aceptado ninguna campa침a y 1 se ha aceptado al menos 1 de las 5 campa침as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AcceptedCmp            1.000000\n",
       "AcceptedCmp4           0.553782\n",
       "AcceptedCmp3           0.551957\n",
       "AcceptedCmp5           0.548292\n",
       "AcceptedCmp1           0.510624\n",
       "MntWines               0.465034\n",
       "Spent                  0.412466\n",
       "Response               0.367401\n",
       "Income                 0.315024\n",
       "NumCatalogPurchases    0.313291\n",
       "MntMeatProducts        0.274626\n",
       "AcceptedCmp2           0.229464\n",
       "NumWebPurchases        0.213228\n",
       "MntGoldProds           0.190782\n",
       "NumStorePurchases      0.186765\n",
       "MntFishProducts        0.160046\n",
       "MntSweetProducts       0.159584\n",
       "MntFruits              0.126553\n",
       "Education              0.047823\n",
       "Age                    0.030778\n",
       "Marital_Status        -0.000198\n",
       "Days                  -0.013751\n",
       "Seniority             -0.013751\n",
       "Recency               -0.017745\n",
       "Complain              -0.027016\n",
       "Year_Birth            -0.030778\n",
       "ID                    -0.041206\n",
       "NumDealsPurchases     -0.086570\n",
       "Teenhome              -0.099415\n",
       "NumWebVisitsMonth     -0.125986\n",
       "Kidhome               -0.203024\n",
       "Child_Home            -0.228974\n",
       "Name: AcceptedCmp, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Correlaci칩n con el Target\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "correlation_with_target = correlation_matrix['AcceptedCmp'].sort_values(ascending=False)\n",
    "correlation_with_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecci칩n de variables X e Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determinamos que las variables con una correlaci칩n entre 0.2 y -0.2 quedar치n excluidas de nuestro entrenamiento, ya que se encuentran entorno al 0 y parecen que no afectan a la variable objetivo y as칤 aligeramos el proceso de entrenamiento.\n",
    "2. Usando una **list comprehension** eliminamos las caracter칤sticas `AcceptedCmp1, AcceptedCmp2, AcceptedCmp3, AcceptedCmp4 y AcceptedCmp5`, ya que son subproducto de AcceptedCmp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracter칤sticas seleccionadas: ['MntWines', 'Spent', 'Response', 'Income', 'NumCatalogPurchases', 'MntMeatProducts', 'NumWebPurchases', 'Kidhome', 'Child_Home']\n"
     ]
    }
   ],
   "source": [
    "# Filtrar correlaciones fuera del rango [-0.2, 0.2]\n",
    "filtered_correlations = correlation_with_target[\n",
    "    correlation_with_target.abs() > 0.2\n",
    "].sort_values(ascending=False)\n",
    "\n",
    "# Lista final de features, excluyendo las variables derivadas de 'AcceptedCmp'\n",
    "excluded_features = ['AcceptedCmp', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5']\n",
    "features = [f for f in filtered_correlations.index if f not in excluded_features]\n",
    "\n",
    "print(\"Caracter칤sticas seleccionadas:\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df['AcceptedCmp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisi칩n de datos\n",
    "Cogeremos el 20% para test y el 80% para training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento del Desbalance de Clases\n",
    "Como vimos en [**EDA**](04_explore_data.ipynb), al final del an치lisis no gr치fico, `AcceptedCmp` tiene la clase est치 desbalanceada.\n",
    "En este escenario, la clase minoritaria (en nuestro caso, la clase 1) est치 significativamente menos representada que la clase mayoritaria (la clase 0). Esto puede generar varios problemas al entrenar un modelo de clasificaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancear clases\n",
    "Optamos por hacer un Submuestreo (**Undersampling**), reduciendo el n칰mero de ejemplos de la clase mayoritaria.\n",
    "\n",
    "Dada la significativa disparidad en la representaci칩n de las clases en nuestro conjunto de datos, con una marcada predominancia de la clase mayoritaria (clase 0), se ha optado por aplicar la t칠cnica de submuestreo (undersampling). El objetivo principal de esta estrategia es reducir el n칰mero de instancias de la clase mayoritaria para mitigar el sesgo del modelo hacia esta clase y mejorar su capacidad para aprender y predecir la clase minoritaria (clase 1) de manera m치s efectiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar undersampling para balancear las clases\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecci칩n de modelos\n",
    "Para el Desbalance de Clases, ajustamos pesos en el modelo (m치s f치cil y eficiente) con `class_weight='balanced`. \n",
    "\n",
    "Como los modelos KNN y Neural Network no son compatibles para que se ajusten, aqu칤 s칤 que aplicaremos el undersampling que se ha hecho previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos con ajuste de pesos para modelos compatibles\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=500, class_weight='balanced'), X_train, y_train),\n",
    "    'KNN': (KNeighborsClassifier(), X_resampled, y_resampled),\n",
    "    'Random Forest': (RandomForestClassifier(class_weight='balanced'), X_train, y_train),\n",
    "    'SVM': (SVC(probability=True, class_weight='balanced'), X_train, y_train),\n",
    "    'Neural Network': (MLPClassifier(), X_resampled, y_resampled)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperpar치metros para GridSearchCV\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7, 9, 11]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 10]},\n",
    "    'SVM': {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]},\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "        'learning_rate': ['constant','adaptive']\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for model_name, (model, X_data, y_data) in models.items():\n",
    "    print(f\"\\nEntrenando {model_name}...\")\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], scoring='roc_auc', n_jobs=-1, cv=5)\n",
    "    grid_search.fit(X_data, y_data)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Best Params': best_params\n",
    "    }\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']] = results_df[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].astype(float)\n",
    "\n",
    "print(\"\\nResultados de los modelos:\")\n",
    "print(results_df)\n",
    "\n",
    "# Determinar el mejor modelo basado en diferentes m칠tricas\n",
    "best_metrics = {metric: results_df[metric].idxmax() for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']}\n",
    "\n",
    "print(\"\\n游댳 Mejores modelos por m칠trica:\")\n",
    "for metric, model in best_metrics.items():\n",
    "    print(f\"Mejor modelo basado en {metric}: {model} - {results_df.at[model, 'Best Params']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing-ml-a6pcPZMr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
